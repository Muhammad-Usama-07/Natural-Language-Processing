{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Usama-07/Natural-Language-Processing/blob/main/NLP_Basics/workFile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dcdbb8c",
      "metadata": {
        "id": "2dcdbb8c"
      },
      "source": [
        "# Regular expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8d65c3f",
      "metadata": {
        "id": "c8d65c3f"
      },
      "source": [
        "## Using Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5fd2532",
      "metadata": {
        "id": "f5fd2532"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26c7b20",
      "metadata": {
        "id": "d26c7b20"
      },
      "source": [
        "## Seperate Sentence on the Basis of sentence endings (. ? !)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb224dd",
      "metadata": {
        "id": "edb224dd",
        "outputId": "f46f34d3-8798-4978-e21a-19d8cb21069e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog', '\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate', '']\n"
          ]
        }
      ],
      "source": [
        "sentence = 'In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog.\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate.'\n",
        "pattern_of_sentence_endings = r\"[.?!]\"\n",
        "print(re.split(pattern_of_sentence_endings, sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec190c5a",
      "metadata": {
        "id": "ec190c5a"
      },
      "source": [
        "## Seperate Words from String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b7d79d",
      "metadata": {
        "id": "f1b7d79d",
        "outputId": "e0ace6dd-0439-4893-fddb-a66184e6ad47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['In', 'linguistics', 'and', 'grammar,', 'a', 'sentence', 'is', 'a', 'linguistic', 'expression']\n"
          ]
        }
      ],
      "source": [
        "sentence = 'In linguistics and grammar, a sentence is a linguistic expression'\n",
        "pattern_of_word_seperation = r\"\\s+\"\n",
        "print(re.split(pattern_of_word_seperation, sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4893e21",
      "metadata": {
        "id": "d4893e21"
      },
      "source": [
        "## Find all capitalized words from String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e60384",
      "metadata": {
        "id": "f3e60384",
        "outputId": "7ba4aab6-c736-4d1d-adf8-514b48a56a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['In', 'Linguistic', 'Expression']\n"
          ]
        }
      ],
      "source": [
        "sentence = 'In linguistics and grammar, a sentence is a Linguistic Expression'\n",
        "capitalized_words_pattern = r\"[A-Z]\\w+\"\n",
        "print(re.findall(capitalized_words_pattern, sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c690d8a2",
      "metadata": {
        "id": "c690d8a2"
      },
      "source": [
        "## Find all Digits from String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4db9da",
      "metadata": {
        "id": "ea4db9da",
        "outputId": "2c18eb11-c8aa-4b25-e7e9-29911cbce32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['2', '123']\n"
          ]
        }
      ],
      "source": [
        "sentence = 'In linguistics and grammar, a 2 sentence is a linguistic expression, 123'\n",
        "find_digit_pattern = r\"\\d+\"\n",
        "print(re.findall(find_digit_pattern, sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search for a first and last occurrence of word  "
      ],
      "metadata": {
        "id": "tvnM7r0ryda2"
      },
      "id": "tvnM7r0ryda2"
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = 'In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog.\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate.'\n",
        "result = re.search(\"and\", paragraph)\n",
        "print(result.start(), result.end())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7QNRNK7yx03",
        "outputId": "b42a163b-86e5-499e-c76f-bb0cb32c057d"
      },
      "id": "m7QNRNK7yx03",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Regex with NLTK Tokenization"
      ],
      "metadata": {
        "id": "CPI1FZHA277N"
      },
      "id": "CPI1FZHA277N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find hashtag from Paragraph"
      ],
      "metadata": {
        "id": "15K_1TiF4Srm"
      },
      "id": "15K_1TiF4Srm"
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "paragraph = 'In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog.\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. #dummytext #hashtagcheck'\n",
        "find_hashtag_pattern = r\"#\\w+\"\n",
        "hashtag_words = regexp_tokenize(paragraph, find_hashtag_pattern)\n",
        "print(hashtag_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mjqzbnQ4agj",
        "outputId": "7048cb1c-7e7c-42bf-94e8-adb872db5d95"
      },
      "id": "6mjqzbnQ4agj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['#dummytext', '#hashtagcheck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find both hashtag and mentions from Paragraph"
      ],
      "metadata": {
        "id": "mwauFr2b5z_x"
      },
      "id": "mwauFr2b5z_x"
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "paragraph = 'In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog.\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. #dummytext #hashtagcheck @today'\n",
        "find_hashtag_pattern = r\"([\\@\\#]\\w+)\"\n",
        "hashtag_words = regexp_tokenize(paragraph, find_hashtag_pattern)\n",
        "print(hashtag_words)"
      ],
      "metadata": {
        "id": "VhAfSFOX53la",
        "outputId": "f28ce0ce-3cc8-4c7f-96df-34b6d63a1f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VhAfSFOX53la",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['#dummytext', '#hashtagcheck', '@today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize Tweets"
      ],
      "metadata": {
        "id": "k2My2-Dq6dU5"
      },
      "id": "k2My2-Dq6dU5"
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "paragraph = ['In linguistics and grammar, a sentence is a linguistic expression', 'such as the English example \"The quick brown fox jumps over the lazy dog.\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. #dummytext #hashtagcheck @today']\n",
        "tknzr_object = TweetTokenizer()\n",
        "all_tokens = [tknzr_object.tokenize(t) for t in paragraph]\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "id": "2kxVXetv6ihj",
        "outputId": "08603b60-65fb-4c5a-c96a-a730da8c6e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2kxVXetv6ihj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['In', 'linguistics', 'and', 'grammar', ',', 'a', 'sentence', 'is', 'a', 'linguistic', 'expression'], ['such', 'as', 'the', 'English', 'example', '\"', 'The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', '\"', 'In', 'traditional', 'grammar', ',', 'it', 'is', 'typically', 'defined', 'as', 'a', 'string', 'of', 'words', 'that', 'expresses', 'a', 'complete', 'thought', ',', 'or', 'as', 'a', 'unit', 'consisting', 'of', 'a', 'subject', 'and', 'predicate', '.', '#dummytext', '#hashtagcheck', '@today']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb9b508",
      "metadata": {
        "id": "aeb9b508"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21cb2ca7",
      "metadata": {
        "id": "21cb2ca7"
      },
      "source": [
        "## Using Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82deaaed",
      "metadata": {
        "id": "82deaaed"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63f8229c",
      "metadata": {
        "id": "63f8229c"
      },
      "source": [
        "## Spliting Paragraph into Sentences "
      ]
    },
    {
      "cell_type": "raw",
      "id": "a6fd9073",
      "metadata": {
        "id": "a6fd9073"
      },
      "source": [
        "To resolve error in doing sent_tokenize use:\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6459f6",
      "metadata": {
        "id": "4e6459f6",
        "outputId": "c581f3dd-0f33-4fbe-9346-fa0bf9f88cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog.\"', 'In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate.']\n"
          ]
        }
      ],
      "source": [
        "paragraph = 'In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog.\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate.'\n",
        "sentences = sent_tokenize(paragraph)\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## filtering tokens"
      ],
      "metadata": {
        "id": "B5Ic3RyaRDPW"
      },
      "id": "B5Ic3RyaRDPW"
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "paragraph = 'In linguistics and grammar, a sentence is a linguistic expression, such as the English example \"The quick brown fox jumps over the lazy dog.\" In traditional grammar, it is typically defined as a string of words that expresses a complete thought #this, or @company as a unit consisting of a subject and predicate.'\n",
        "word_tokens = word_tokenize(paragraph)\n",
        "letters_tokens = [a_word for a_word in word_tokens if a_word.isalpha()]\n",
        "print('letters tokens: ', letters_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX2zhsTORHgI",
        "outputId": "0264e70f-7c0e-4b62-f7f4-83648f8092cf"
      },
      "id": "UX2zhsTORHgI",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned tokens:  ['In', 'linguistics', 'and', 'grammar', 'a', 'sentence', 'is', 'a', 'linguistic', 'expression', 'such', 'as', 'the', 'English', 'example', 'The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'In', 'traditional', 'grammar', 'it', 'is', 'typically', 'defined', 'as', 'a', 'string', 'of', 'words', 'that', 'expresses', 'a', 'complete', 'thought', 'this', 'or', 'company', 'as', 'a', 'unit', 'consisting', 'of', 'a', 'subject', 'and', 'predicate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find emoji only"
      ],
      "metadata": {
        "id": "ej2E0V8xuAV6"
      },
      "id": "ej2E0V8xuAV6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3243ef",
      "metadata": {
        "id": "5a3243ef",
        "outputId": "01605a24-541a-485a-860f-01e3c7807f70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['üöï', 'üçï']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "st = 'I like driving üöï and eating üçï'\n",
        "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
        "print(regexp_tokenize(st, emoji))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6CNQdvUfuodn"
      },
      "id": "6CNQdvUfuodn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}